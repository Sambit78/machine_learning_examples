{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:\n",
      "---------------------------\n",
      "-0.10|-0.10|-0.10| 1.00|\n",
      "---------------------------\n",
      "-0.10| 0.00|-0.10|-1.00|\n",
      "---------------------------\n",
      "-0.10|-0.10|-0.10|-0.10|\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final values:\n",
      "---------------------------\n",
      " 0.58| 0.78| 1.00| 0.00|\n",
      "---------------------------\n",
      " 0.41| 0.00| 0.78| 0.00|\n",
      "---------------------------\n",
      " 0.25| 0.12| 0.62| 0.00|\n",
      "final policy:\n",
      "---------------------------\n",
      "  R  |  R  |  R  |     |\n",
      "---------------------------\n",
      "  U  |     |  U  |     |\n",
      "---------------------------\n",
      "  U  |  L  |  U  |  D  |\n"
     ]
    }
   ],
   "source": [
    "# https://deeplearningcourses.com/c/artificial-intelligence-reinforcement-learning-in-python\n",
    "# https://www.udemy.com/artificial-intelligence-reinforcement-learning-in-python\n",
    "from __future__ import print_function, division\n",
    "from builtins import range\n",
    "# Note: you may need to update your version of future\n",
    "# sudo pip install -U future\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from grid_world import standard_grid, negative_grid\n",
    "from iterative_policy_evaluation import print_values, print_policy\n",
    "from monte_carlo_es import max_dict\n",
    "\n",
    "GAMMA = 0.9\n",
    "ALL_POSSIBLE_ACTIONS = ('U', 'D', 'L', 'R')\n",
    "\n",
    "# NOTE: find optimal policy and value function\n",
    "#       using on-policy first-visit MC\n",
    "\n",
    "def random_action(a, eps=0.1):\n",
    "  # choose given a with probability 1 - eps + eps/4\n",
    "  # choose some other a' != a with probability eps/4\n",
    "  p = np.random.random()\n",
    "  # if p < (1 - eps + eps/len(ALL_POSSIBLE_ACTIONS)):\n",
    "  #   return a\n",
    "  # else:\n",
    "  #   tmp = list(ALL_POSSIBLE_ACTIONS)\n",
    "  #   tmp.remove(a)\n",
    "  #   return np.random.choice(tmp)\n",
    "  #\n",
    "  # this is equivalent to the above\n",
    "  if p < (1 - eps):\n",
    "    return a\n",
    "  else:\n",
    "    return np.random.choice(ALL_POSSIBLE_ACTIONS)\n",
    "\n",
    "def play_game(grid, policy):\n",
    "  # returns a list of states and corresponding returns\n",
    "  # in this version we will NOT use \"exploring starts\" method\n",
    "  # instead we will explore using an epsilon-soft policy\n",
    "  s = (2, 0)\n",
    "  grid.set_state(s)\n",
    "  a = random_action(policy[s])\n",
    "\n",
    "  # be aware of the timing\n",
    "  # each triple is s(t), a(t), r(t)\n",
    "  # but r(t) results from taking action a(t-1) from s(t-1) and landing in s(t)\n",
    "  states_actions_rewards = [(s, a, 0)]\n",
    "  while True:\n",
    "    r = grid.move(a)\n",
    "    s = grid.current_state()\n",
    "    if grid.game_over():\n",
    "      states_actions_rewards.append((s, None, r))\n",
    "      break\n",
    "    else:\n",
    "      a = random_action(policy[s]) # the next state is stochastic\n",
    "      states_actions_rewards.append((s, a, r))\n",
    "\n",
    "  # calculate the returns by working backwards from the terminal state\n",
    "  G = 0\n",
    "  states_actions_returns = []\n",
    "  first = True\n",
    "  for s, a, r in reversed(states_actions_rewards):\n",
    "    # the value of the terminal state is 0 by definition\n",
    "    # we should ignore the first state we encounter\n",
    "    # and ignore the last G, which is meaningless since it doesn't correspond to any move\n",
    "    if first:\n",
    "      first = False\n",
    "    else:\n",
    "      states_actions_returns.append((s, a, G))\n",
    "    G = r + GAMMA*G\n",
    "  states_actions_returns.reverse() # we want it to be in order of state visited\n",
    "  return states_actions_returns\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  # use the standard grid again (0 for every step) so that we can compare\n",
    "  # to iterative policy evaluation\n",
    "  # grid = standard_grid()\n",
    "  # try the negative grid too, to see if agent will learn to go past the \"bad spot\"\n",
    "  # in order to minimize number of steps\n",
    "  grid = negative_grid(step_cost=-0.1)\n",
    "\n",
    "  # print rewards\n",
    "  print(\"rewards:\")\n",
    "  print_values(grid.rewards, grid)\n",
    "\n",
    "  # state -> action\n",
    "  # initialize a random policy\n",
    "  policy = {}\n",
    "  for s in grid.actions.keys():\n",
    "    policy[s] = np.random.choice(ALL_POSSIBLE_ACTIONS)\n",
    "\n",
    "  # initialize Q(s,a) and returns\n",
    "  Q = {}\n",
    "  returns = {} # dictionary of state -> list of returns we've received\n",
    "  states = grid.all_states()\n",
    "  for s in states:\n",
    "    if s in grid.actions: # not a terminal state\n",
    "      Q[s] = {}\n",
    "      for a in ALL_POSSIBLE_ACTIONS:\n",
    "        Q[s][a] = 0\n",
    "        returns[(s,a)] = []\n",
    "    else:\n",
    "      # terminal state or state we can't otherwise get to\n",
    "      pass\n",
    "\n",
    "  # repeat until convergence\n",
    "  deltas = []\n",
    "  for t in range(5000):\n",
    "    if t % 1000 == 0:\n",
    "      print(t)\n",
    "\n",
    "    # generate an episode using pi\n",
    "    biggest_change = 0\n",
    "    states_actions_returns = play_game(grid, policy)\n",
    "\n",
    "    # calculate Q(s,a)\n",
    "    seen_state_action_pairs = set()\n",
    "    for s, a, G in states_actions_returns:\n",
    "      # check if we have already seen s\n",
    "      # called \"first-visit\" MC policy evaluation\n",
    "      sa = (s, a)\n",
    "      if sa not in seen_state_action_pairs:\n",
    "        old_q = Q[s][a]\n",
    "        returns[sa].append(G)\n",
    "        Q[s][a] = np.mean(returns[sa])\n",
    "        biggest_change = max(biggest_change, np.abs(old_q - Q[s][a]))\n",
    "        seen_state_action_pairs.add(sa)\n",
    "    deltas.append(biggest_change)\n",
    "\n",
    "    # calculate new policy pi(s) = argmax[a]{ Q(s,a) }\n",
    "    for s in policy.keys():\n",
    "      a, _ = max_dict(Q[s])\n",
    "      policy[s] = a\n",
    "\n",
    "  plt.plot(deltas)\n",
    "  plt.show()\n",
    "\n",
    "  # find the optimal state-value function\n",
    "  # V(s) = max[a]{ Q(s,a) }\n",
    "  V = {}\n",
    "  for s in policy.keys():\n",
    "    V[s] = max_dict(Q[s])[1]\n",
    "\n",
    "  print(\"final values:\")\n",
    "  print_values(V, grid)\n",
    "  print(\"final policy:\")\n",
    "  print_policy(policy, grid)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
