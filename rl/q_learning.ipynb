{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:\n",
      "---------------------------\n",
      "-0.10|-0.10|-0.10| 1.00|\n",
      "---------------------------\n",
      "-0.10| 0.00|-0.10|-1.00|\n",
      "---------------------------\n",
      "-0.10|-0.10|-0.10|-0.10|\n",
      "it: 0\n",
      "it: 2000\n",
      "it: 4000\n",
      "it: 6000\n",
      "it: 8000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAY50lEQVR4nO3df5Rc5X3f8fdHu0hCSAj9WEAg4ZUs2UQ+NImRBbTG5ZgaC6ex2gaORXJqkdKDW5cTp06PK+pjjIlPEogLtYsSQwMuJTGCkDhWjUAGJNunMchagUHIktBqASHxQ7uSWPRb++PbP+aumB1md+9qZ3d2n/m8ztmjO8995s737l195s5z79yriMDMzNI1rtoFmJnZ8HLQm5klzkFvZpY4B72ZWeIc9GZmiauvdgGlZs6cGY2NjdUuw8xsTNm0aVNbRDSUmzfqgr6xsZGmpqZql2FmNqZIeq2veR66MTNLnIPezCxxDnozs8Q56M3MEuegNzNLXK6gl7RE0nZJzZJWlJn/CUnPSeqUdE3JvOWSdmQ/yytVuJmZ5TNg0EuqA1YCVwMLgeskLSzptgu4Hvh+yXOnA18HLgEWA1+XNG3oZZuZWV559ugXA80R0RIRJ4BVwNLiDhHxakS8CHSXPPfTwJMRsT8iDgBPAksqUPf7vNV+jJXrm2k/2jEcizczG7PyBP35wOtFj3dnbXnkeq6kGyU1SWpqbW3NuejeNu9p58/XbuenL5/a883MUjUqDsZGxL0RsSgiFjU0lP0G74Dmnz0ZgK7u0g8VZma1LU/Q7wHmFD2enbXlMZTnDoqGY6FmZgnIE/QbgQWS5koaDywDVudc/lrgKknTsoOwV2Vtw8Z3RjQz623AoI+ITuAmCgG9FXgkIrZIuk3SZwEkfUzSbuBa4B5JW7Ln7gf+mMKbxUbgtqyt4uRdejOzsnJdvTIi1gBrStpuKZreSGFYptxz7wfuH0KNg+I9ejOz3kbFwdhKUDZK75w3M+stnaD30I2ZWVnJBH2P8NiNmVkv6QV9tQswMxtlkgl6D92YmZWXTNCf5F16M7Nekgl6eZfezKysZIK+R3iX3sysl2SCvmd/3ifdmJn1lk7Qe+TGzKysZIK+h3fozcx6SyboT14CwUlvZtZLOkHvoRszs7KSCfoeD/1iV7VLMDMbVZIJ+p4d+s172qtah5nZaJNM0JuZWXnpBL3H6M3Mykom6OWkNzMrK5mgNzOz8pIJep9eaWZWXjpBX+0CzMxGqWSC3szMyksm6H09ejOz8pIJejMzKy+ZoPf+vJlZeekEvZPezKysZILezMzKSybo/c1YM7Pykgl6MzMrL52g9w69mVlZyQS9D8aamZWXK+glLZG0XVKzpBVl5k+Q9HA2f4Okxqz9NEkPSNosaaukmytbfnlb3vDNR8zMegwY9JLqgJXA1cBC4DpJC0u63QAciIj5wF3A7Vn7tcCEiLgIuBj4Qs+bQKUV79D/r5+1DMdLmJmNSXn26BcDzRHREhEngFXA0pI+S4EHsulHgStVuCZBAGdIqgdOB04A71ak8hK+BIKZWXl5gv584PWix7uztrJ9IqITaAdmUAj9w8CbwC7gWxGxv/QFJN0oqUlSU2tr66BXwszM+jbcB2MXA13AecBc4I8kzSvtFBH3RsSiiFjU0NBwSi/k/Xkzs/LyBP0eYE7R49lZW9k+2TDNVGAf8LvAExHRERF7gX8EFg21aDMzyy9P0G8EFkiaK2k8sAxYXdJnNbA8m74GWBcRQWG45pMAks4ALgW2VaLwUsVD9DEcL2BmNkYNGPTZmPtNwFpgK/BIRGyRdJukz2bd7gNmSGoGvgz0nIK5EpgsaQuFN4zvRcSLlV4J6H0JhHDSm5mdVJ+nU0SsAdaUtN1SNH2MwqmUpc87VK7dzMxGjr8Za2aWuGSC3szMynPQm5klLpmg99CNmVl5yQS9mZmVl0zQ+w5TZmblpRP0znkzs7KSCfpiq194g7/4SXO1yzAzGxWSCfrSHfo7nthelTrMzEabdILeYzdmZmUlE/RmZlZeMkHv/Xkzs/KSCXozMysvmaD3EL2ZWXkJBb2T3sysnGSC3szMynPQm5klzkFvZpY4B72ZWeIc9GZmiXPQm5klzkFvZpa4pIP+7XePVbsEM7OqSzroO7q6q12CmVnVJR30EdWuwMys+pIOejMzc9CbmSXPQW9mljgHvZlZ4hz0ZmaJyxX0kpZI2i6pWdKKMvMnSHo4m79BUmPRvH8i6RlJWyRtljSxcuX3z2fdmJnlCHpJdcBK4GpgIXCdpIUl3W4ADkTEfOAu4PbsufXAXwP/ISI+AlwBdFSsejMzG1CePfrFQHNEtETECWAVsLSkz1LggWz6UeBKFW75dBXwYkS8ABAR+yKiqzKlm5lZHnmC/nzg9aLHu7O2sn0iohNoB2YAHwJC0lpJz0n6SrkXkHSjpCZJTa2trYNdBzMz68dwH4ytBz4O/F7277+WdGVpp4i4NyIWRcSihoaGir14ED3L58FnXuXgMY8amVntyRP0e4A5RY9nZ21l+2Tj8lOBfRT2/n8WEW0RcQRYA3x0qEUP1jMt+/jaD7fw9R9uGemXNjOrujxBvxFYIGmupPHAMmB1SZ/VwPJs+hpgXUQEsBa4SNKk7A3gnwO/qkzp+R3rKBwWOHDkxEi/tJlZ1dUP1CEiOiXdRCG064D7I2KLpNuApohYDdwHPCipGdhP4c2AiDgg6U4KbxYBrImIx4ZpXczMrIwBgx4gItZQGHYpbrulaPoYcG0fz/1rCqdYjjifR29m5m/GmpklL+mg9w69mVniQd/DQzhmVstqIujNzGpZTQS9VO0KzMyqpyaC3sysliUd9OHBeTOztIO+1Prtrfz52m3VLsPMbETVVNADrFy/s9olmJmNqJoLejOzWpN00HuE3sws8aA3MzMHvZlZ8hz0ZmaJSzrofRq9mVniQW9mZg56M7Pk1WTQ99xD1sysFiQe9OUH6W9dvWWE6zAzq57Eg768rW8drHYJZmYjJumg7/OsG5+OY2Y1pL7aBQy3NZvfpKOru9plmJlVTdJB39J2mC/+zXPUjet9iynvz5tZLUl66OboicLZNV3djnYzq11JB314393MLO2g74uPxZpZLanJoDczqyU1GfSb97TzbMu+apdhZjYikg76Q8f7vtTB3euaR7ASM7PqSTrov/YPL1W7BDOzqks66M3MLGfQS1oiabukZkkrysyfIOnhbP4GSY0l8y+QdEjSf6lM2WZmlteAQS+pDlgJXA0sBK6TtLCk2w3AgYiYD9wF3F4y/07g8aGXa2Zmg5Vnj34x0BwRLRFxAlgFLC3psxR4IJt+FLhSkgAk/SvgFWBUXRvYX6Yys1qRJ+jPB14verw7ayvbJyI6gXZghqTJwH8FvtHfC0i6UVKTpKbW1ta8tZuZWQ7DfTD2VuCuiDjUX6eIuDciFkXEooaGhmEuqbfNu9t5+91jI/qaZmYjKc/VK/cAc4oez87ayvXZLakemArsAy4BrpF0B3AW0C3pWETcPeTKK+S37/5/nH5aHVv/eEm1SzEzGxZ5gn4jsEDSXAqBvgz43ZI+q4HlwDPANcC6iAjg8p4Okm4FDo2mkO9x1PeQNbOEDRj0EdEp6SZgLVAH3B8RWyTdBjRFxGrgPuBBSc3AfgpvBqOaL2xmZrUi141HImINsKak7Zai6WPAtQMs49ZTqM/MzIaoZr8ZKw3cx8wsBTUb9GZmtcJBb2aWuJoNeh+MNbNaUbNBb2ZWKxz0ZmaJc9CbmSXOQW9mlriaDXofjDWzWlGzQW9mVisc9GZmiXPQm5klrmaD3te6MbNakVTQz552erVLMDMbdZIK+sHwWTdmViuSCvqPnHdmtUswMxt1kgr6ZYsvOOXnRgR3Pvkyb7X7RuFmlpakgn4wgt5jN5v3tPOdp3fwpVXPV6kiM7PhUbNB/2zL/l6Pu7oLwX+ss7sa5ZiZDZuaDXozs1rhoM/4JBwzS5WDvoS/R2VmqUkq6H/t3FM/vXL9tr0A/PL1d2hc8VilSjIzq7qkgv7cqRNP+bn/c11zBSsxMxs9kgp6MzN7Pwe9mVniHPRmZomr6aDf2Xqoz3nHO7tGsBIzs+FT00H/+OY3+5x35LiD3szSUNNB/8Lu9mqXYGY27HIFvaQlkrZLapa0osz8CZIezuZvkNSYtX9K0iZJm7N/P1nZ8ofGV6o0s1owYNBLqgNWAlcDC4HrJC0s6XYDcCAi5gN3Abdn7W3Ab0fERcBy4MFKFV4J/d1OcM1LfQ/rmJmNJXn26BcDzRHREhEngFXA0pI+S4EHsulHgSslKSKej4g3svYtwOmSJlSi8Ero7y5TX/3BS3R0+UqWZjb25Qn684HXix7vztrK9omITqAdmFHS53eA5yLieOkLSLpRUpOkptbW1ry1m5lZDiNyMFbSRygM53yh3PyIuDciFkXEooaGhpEoKRffV9bMUpAn6PcAc4oez87ayvaRVA9MBfZlj2cDPwA+HxE7h1pwJW17691+5z+x5S2Odfg0SzMb2/IE/UZggaS5ksYDy4DVJX1WUzjYCnANsC4iQtJZwGPAioj4x0oVXSkdXf3vsv/BQ8/zJ2u2jlA1ZmbDY8Cgz8bcbwLWAluBRyJii6TbJH0263YfMENSM/BloOcUzJuA+cAtkn6Z/Zxd8bUYRnsOHK12CWZmQ1Kfp1NErAHWlLTdUjR9DLi2zPO+CXxziDVWlYfpzWysq+lvxuaxLrshiZnZWOWgNzNLnIPezCxxDnozs8Q56M3MEpdc0DfOmFTtEszMRpXkgn7yxFxnjA7JptcO8NyuA8P+OmZmlTD8qTjCRD/XHq6Q3/nLnwPw6p/91rC/lpnZUCW3R29mZr056HOIfi5jeeeTL/P1H740gtWYmQ2Ogz6HlrbDfc77ztM7eOCZ10awGjOzwUku6D/3sTkDdxqkru7g9f1H+u2zdstbFX9dM7NKSC7o50yv/OmV335qB5ffsZ7X9vW9Z/+FBzexeXd7xV/bzGyokgv6X589teLL/PnONgDefvd9d0HspaXtEPsO9d/HzGykJRf0Z00aX/FlHjjSAcAjTa/32+9Lq37Jxd98quKvb2Y2FMkF/XD6vy+8kavfq22HaT3oPXszGx2S+8LUaHDFt34C+AtVZjY6eI9+EDTIL93+9OXW4SnEzGwQHPRD8M6RE/3OX37/L0aoEjOzvjnoB+FYR3evxwOdhQPQuOIxNr3mC6CZWfU46Aepu/u9yyHsO5zvgOv3N+zinp/u7PdSCmZmwyXJoL/+nzYO27Lv+VnLoJ/zd8/t5k8f38bPdrQNQ0VmZv1LMuhv+uT8YVv27U9se+/BIHfQr/+ex+zNbOQlGfSjVc/ITXd3cKyjq7rFmFnNcNAPQfcpDrn/0d++wIVfe4KjJ7o4eKyjskWZmZVIMuhH6phn9ym80M7WQ/zg+T0AXH7Hei669ce0H3XYm9nwSTLoR8oTp3Bp4iv/+09PTrdlF0D79W/8eMDLIJuZnSoH/RB8f8Ouii3r8jvWc8P/3lix5ZmZ9XDQjyJPb9tL44rH6OzqHrizmVlOSQb9jDMqf6nikXTtPc9w7Xd/zvHOwpk567ft5egJn6VjZqcmyatXjhs3yKuPjTLP73oHgJXrmrnsgzP5/WxI54k/vJy2gyf4+IKZ1SzPzMYY5flavqQlwLeBOuCvIuLPSuZPAP4PcDGwD/hcRLyazbsZuAHoAv4gItb291qLFi2Kpqamwa9Jid+47ce8cyTNs1k2/Lcruf57G7l8wUzmTJ9E/Thx2bwZ1I0TdePErKkT0WAvtWlmY5qkTRGxqNy8AffoJdUBK4FPAbuBjZJWR8SvirrdAByIiPmSlgG3A5+TtBBYBnwEOA94StKHImLYxyEuPHcKz7bsH+6XqYpL/uRpALa++e6AfS/+wDT+7aUf4JJ50zn3zPfeAJ761dtcOGsKs6cV7rF7orOb7ggmnlZ38rnd3UFndzC+fhz7Dh1nx95DXDpvxsn5rQePc+DICaZMrKdunDh7ysQhrdcb7xzlrEmnMWn86Pyg2dUd7D14jFlTT8/df5wY0pvukROdALl+JxHBoeOdTJl42snjPPV1wzM629Ud1I3xT861JM//qMVAc0S0AEhaBSwFioN+KXBrNv0ocLcKf91LgVURcRx4RVJztrxnKlN+3754xXyebfElBza9dqDX1TMnja/j3DMn0tJWuNH5grMnA7Bj7yEA5mePVdS24OzJJ6fnNZxBXRZcPW09epZ1qopfr9IqseyeZcycPJ5pOW5Z2dO/YcoEWg8ef9/zWg8d550jHcybeUafoTmYunv6Tj39tPd9N6OvmvcfPkH70Q4+MGMS43K+IZ38W8jq3rH3ENMmncbMyRPo6g5a2g4zZ/rpTKyvG2BJ7zna0cXuA0dpnDGJ04bpzWksuOLDDXz1txZWfLl5gv58oPhmqbuBS/rqExGdktqBGVn7syXPPb/0BSTdCNwIcMEFF+StvV+f+FADX7zig/zFT3Zy3eILeOgXlTsVcizr7A5+bdaZtLQd5sJzpzCv4QwAdu0/wvHObj58zhQiu4jPkRNd7HnnKAvOee/N4MJzp5xc1qHjnbzZfgyA8fXjTvY7VTv2HmLO9NOHvJxy9h48TvvRjiEte8rEep7b9Q4fa5ye6yY0PevzwYbJ/GR7KwvPm8rkCe+FX8/yPnTOFMb1kW2vtB0mIFfdMyaP59mW/VwydzrPtOzj4LHOk/MumD6Jc6e+/xNX26ET/OKV/Sw4u+8aStXXjWPrm+9y4awpJ9dz8sR6FpwzmQhoaTvM2VMmcs6ZE/ItkMInyt0HjnLBjDN6/Y5qzTlnDu1TcV9GxWfkiLgXuBcKY/SVWu5XllzIV5ZcCMCf/puLKrXYJKysdgFmNmLyvIfvAeYUPZ6dtZXtI6kemErhoGye55qZ2TDKE/QbgQWS5koaT+Hg6uqSPquB5dn0NcC6KJzOsxpYJmmCpLnAAsAD52ZmI2jAoZtszP0mYC2F0yvvj4gtkm4DmiJiNXAf8GB2sHU/hTcDsn6PUDhw2wn8p5E448bMzN6T6zz6kVSp8+jNzGpJf+fR1+55TGZmNcJBb2aWOAe9mVniHPRmZokbdQdjJbUCrw1hETOBtgqVMxbU2vqC17lWeJ0H5wMR0VBuxqgL+qGS1NTXkecU1dr6gte5VnidK8dDN2ZmiXPQm5klLsWgv7faBYywWltf8DrXCq9zhSQ3Rm9mZr2luEdvZmZFHPRmZolLJuglLZG0XVKzpBXVrmcoJM2RtF7SryRtkfSlrH26pCcl7cj+nZa1S9J3snV/UdJHi5a1POu/Q9Lyvl5zNJBUJ+l5ST/KHs+VtCFbr4ezy2STXfb64ax9g6TGomXcnLVvl/Tp6qxJPpLOkvSopG2Stkq6rAa28X/O/qZfkvSQpImpbWdJ90vaK+mloraKbVdJF0vanD3nO1KO+51FxJj/oXD55J3APGA88AKwsNp1DWF9ZgEfzaanAC8DC4E7gBVZ+wrg9mz6M8DjFG71eimwIWufDrRk/07LpqdVe/36We8vA98HfpQ9fgRYlk1/F/iP2fQXge9m08uAh7Pphdm2nwDMzf4m6qq9Xv2s7wPAv8+mxwNnpbyNKdxG9BXg9KLte31q2xn4BPBR4KWitoptVwr39Lg0e87jwNUD1lTtX0qFfrGXAWuLHt8M3Fztuiq4fj8EPgVsB2ZlbbOA7dn0PcB1Rf23Z/OvA+4pau/VbzT9ULj72NPAJ4EfZX/EbUB96TamcG+Ey7Lp+qyfSrd7cb/R9kPhLmyvkJ0QUbrtEt3GPfeWnp5ttx8Bn05xOwONJUFfke2azdtW1N6rX18/qQzdlLuB+ftuQj4WZR9XfxPYAJwTEW9ms94Czsmm+1r/sfR7+R/AV4Du7PEM4J2I6LnDdXHtvW5GDxTfjH6srO9coBX4XjZc9VeSziDhbRwRe4BvAbuANylst02kvZ17VGq7np9Nl7b3K5WgT5KkycDfAX8YEe8Wz4vC23kS58ZK+pfA3ojYVO1aRlA9hY/3fxkRvwkcpvCR/qSUtjFANi69lMKb3HnAGcCSqhZVBdXYrqkEfXI3IZd0GoWQ/5uI+Pus+W1Js7L5s4C9WXtf6z9Wfi//DPispFeBVRSGb74NnKXCzeahd+0p3Ix+N7A7IjZkjx+lEPypbmOAfwG8EhGtEdEB/D2FbZ/ydu5Rqe26J5sube9XKkGf5wbmY0Z2FP0+YGtE3Fk0q/gm7MspjN33tH8+O4J/KdCefUxcC1wlaVq2N3VV1jaqRMTNETE7IhopbLt1EfF7wHoKN5uH96/vmL4ZfUS8Bbwu6cNZ05UU7q2c5DbO7AIulTQp+xvvWedkt3ORimzXbN67ki7NfoefL1pW36p90KKCBz8+Q+HslJ3AV6tdzxDX5eMUPtq9CPwy+/kMhfHJp4EdwFPA9Ky/gJXZum8GFhUt698BzdnP71d73XKs+xW8d9bNPAr/gZuBvwUmZO0Ts8fN2fx5Rc//avZ72E6OsxGqvK6/ATRl2/kfKJxdkfQ2Br4BbANeAh6kcOZMUtsZeIjCMYgOCp/cbqjkdgUWZb+/ncDdlBzQL/fjSyCYmSUulaEbMzPrg4PezCxxDnozs8Q56M3MEuegNzNLnIPezCxxDnozs8T9f5Q6hurRyJo1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update counts:\n",
      "---------------------------\n",
      " 0.15| 0.15| 0.17| 0.00|\n",
      "---------------------------\n",
      " 0.15| 0.00| 0.06| 0.00|\n",
      "---------------------------\n",
      " 0.19| 0.06| 0.06| 0.01|\n",
      "values:\n",
      "---------------------------\n",
      " 0.62| 0.80| 1.00| 0.00|\n",
      "---------------------------\n",
      " 0.46| 0.00| 0.80| 0.00|\n",
      "---------------------------\n",
      " 0.31| 0.46| 0.62| 0.46|\n",
      "policy:\n",
      "---------------------------\n",
      "  R  |  R  |  R  |     |\n",
      "---------------------------\n",
      "  U  |     |  U  |     |\n",
      "---------------------------\n",
      "  U  |  R  |  U  |  L  |\n"
     ]
    }
   ],
   "source": [
    "# https://deeplearningcourses.com/c/artificial-intelligence-reinforcement-learning-in-python\n",
    "# https://www.udemy.com/artificial-intelligence-reinforcement-learning-in-python\n",
    "from __future__ import print_function, division\n",
    "from builtins import range\n",
    "# Note: you may need to update your version of future\n",
    "# sudo pip install -U future\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from grid_world import standard_grid, negative_grid\n",
    "from iterative_policy_evaluation import print_values, print_policy\n",
    "from monte_carlo_es import max_dict\n",
    "from td0_prediction import random_action\n",
    "\n",
    "GAMMA = 0.9\n",
    "ALPHA = 0.1\n",
    "ALL_POSSIBLE_ACTIONS = ('U', 'D', 'L', 'R')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  # NOTE: if we use the standard grid, there's a good chance we will end up with\n",
    "  # suboptimal policies\n",
    "  # e.g.\n",
    "  # ---------------------------\n",
    "  #   R  |   R  |   R  |      |\n",
    "  # ---------------------------\n",
    "  #   R* |      |   U  |      |\n",
    "  # ---------------------------\n",
    "  #   U  |   R  |   U  |   L  |\n",
    "  # since going R at (1,0) (shown with a *) incurs no cost, it's OK to keep doing that.\n",
    "  # we'll either end up staying in the same spot, or back to the start (2,0), at which\n",
    "  # point we whould then just go back up, or at (0,0), at which point we can continue\n",
    "  # on right.\n",
    "  # instead, let's penalize each movement so the agent will find a shorter route.\n",
    "  #\n",
    "  # grid = standard_grid()\n",
    "  grid = negative_grid(step_cost=-0.1)\n",
    "\n",
    "  # print rewards\n",
    "  print(\"rewards:\")\n",
    "  print_values(grid.rewards, grid)\n",
    "\n",
    "  # no policy initialization, we will derive our policy from most recent Q\n",
    "\n",
    "  # initialize Q(s,a)\n",
    "  Q = {}\n",
    "  states = grid.all_states()\n",
    "  for s in states:\n",
    "    Q[s] = {}\n",
    "    for a in ALL_POSSIBLE_ACTIONS:\n",
    "      Q[s][a] = 0\n",
    "\n",
    "  # let's also keep track of how many times Q[s] has been updated\n",
    "  update_counts = {}\n",
    "  update_counts_sa = {}\n",
    "  for s in states:\n",
    "    update_counts_sa[s] = {}\n",
    "    for a in ALL_POSSIBLE_ACTIONS:\n",
    "      update_counts_sa[s][a] = 1.0\n",
    "\n",
    "  # repeat until convergence\n",
    "  t = 1.0\n",
    "  deltas = []\n",
    "  for it in range(10000):\n",
    "    if it % 100 == 0:\n",
    "      t += 1e-2\n",
    "    if it % 2000 == 0:\n",
    "      print(\"it:\", it)\n",
    "\n",
    "    # instead of 'generating' an epsiode, we will PLAY\n",
    "    # an episode within this loop\n",
    "    s = (2, 0) # start state\n",
    "    grid.set_state(s)\n",
    "\n",
    "    # the first (s, r) tuple is the state we start in and 0\n",
    "    # (since we don't get a reward) for simply starting the game\n",
    "    # the last (s, r) tuple is the terminal state and the final reward\n",
    "    # the value for the terminal state is by definition 0, so we don't\n",
    "    # care about updating it.\n",
    "    a, _ = max_dict(Q[s])\n",
    "    biggest_change = 0\n",
    "    while not grid.game_over():\n",
    "      a = random_action(a, eps=0.5/t) # epsilon-greedy\n",
    "      # random action also works, but slower since you can bump into walls\n",
    "      # a = np.random.choice(ALL_POSSIBLE_ACTIONS)\n",
    "      r = grid.move(a)\n",
    "      s2 = grid.current_state()\n",
    "    \n",
    "    \n",
    "      # adaptive learning rate \n",
    "    \n",
    "      alpha = ALPHA / update_counts_sa[s][a]\n",
    "      update_counts_sa[s][a] += 0.005\n",
    "\n",
    "      # we will update Q(s,a) AS we experience the episode\n",
    "      old_qsa = Q[s][a]\n",
    "      # the difference between SARSA and Q-Learning is with Q-Learning\n",
    "      # we will use this max[a']{ Q(s',a')} in our update\n",
    "      # even if we do not end up taking this action in the next step\n",
    "      a2, max_q_s2a2 = max_dict(Q[s2])\n",
    "      Q[s][a] = Q[s][a] + ALPHA*(r + GAMMA*max_q_s2a2 - Q[s][a])\n",
    "      biggest_change = max(biggest_change, np.abs(old_qsa - Q[s][a]))\n",
    "\n",
    "      # we would like to know how often Q(s) has been updated too\n",
    "      update_counts[s] = update_counts.get(s,0) + 1\n",
    "\n",
    "      # next state becomes current state\n",
    "      s = s2\n",
    "      a = a2\n",
    "     \n",
    "    deltas.append(biggest_change)\n",
    "\n",
    "  plt.plot(deltas)\n",
    "  plt.show()\n",
    "\n",
    "  # determine the policy from Q*\n",
    "  # find V* from Q*\n",
    "  policy = {}\n",
    "  V = {}\n",
    "  for s in grid.actions.keys():\n",
    "    a, max_q = max_dict(Q[s])\n",
    "    policy[s] = a\n",
    "    V[s] = max_q\n",
    "\n",
    "  # what's the proportion of time we spend updating each part of Q?\n",
    "  print(\"update counts:\")\n",
    "  total = np.sum(list(update_counts.values()))\n",
    "  for k, v in update_counts.items():\n",
    "    update_counts[k] = float(v) / total\n",
    "  print_values(update_counts, grid)\n",
    "\n",
    "  print(\"values:\")\n",
    "  print_values(V, grid)\n",
    "  print(\"policy:\")\n",
    "  print_policy(policy, grid)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
